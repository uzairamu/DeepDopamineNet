{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b5576e4-9593-4f68-82d3-b7f25b879d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCNConv,TopKPooling,global_mean_pool\n",
    "from torch_geometric.nn import global_mean_pool as gmp, global_max_pool as gap\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader,random_split\n",
    "import tqdm\n",
    "from torch_geometric.data import DataLoader, Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456897b1-fb78-4ce6-a09c-b4681077e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"drug.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b2b00b3-6998-4f9b-b39c-648f9882b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_id = df[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0aa4d70-cdff-4e6c-b56f-1fe2cc196f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_df = pd.read_csv(\"smiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2177e0d7-f55c-490b-af64-936b8e510497",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = smiles_df[\"Smiles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3847b92a-4d3e-4f98-af0f-c4b8ecf1893e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:49:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[13:49:48] WARNING: not removing hydrogen atom without neighbors\n",
      "[13:49:58] WARNING: not removing hydrogen atom without neighbors\n",
      "[13:50:18] WARNING: not removing hydrogen atom without neighbors\n",
      "[13:50:18] WARNING: not removing hydrogen atom without neighbors\n",
      "[13:50:18] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "drug_cleaned=[]\n",
    "smiles_cleaned=[]\n",
    "for i in range(len(smiles)):\n",
    "       if isinstance(smiles[i], str) and not pd.isnull(smiles[i]):\n",
    "        mol_obj = Chem.MolFromSmiles(smiles[i])\n",
    "        if mol_obj is not None:\n",
    "            # If successful, add drug_id and smiles to the cleaned lists\n",
    "            drug_cleaned.append(drug_id[i])\n",
    "            smiles_cleaned.append(smiles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40e2451b-452b-486b-910d-2d24e67ad989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048575\n",
      "1036742\n"
     ]
    }
   ],
   "source": [
    "print(len(smiles))\n",
    "print(len(drug_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6887006-e2bf-4986-b326-109814e25d19",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_node_features(mol):\n",
    "        \"\"\"\n",
    "        This will return a matrix / 2d array of the shape\n",
    "        [Number of Nodes, Node Feature size]\n",
    "        \"\"\"\n",
    "        all_node_feats = []\n",
    "\n",
    "        for atom in mol.GetAtoms():\n",
    "            node_feats = []\n",
    "            # Feature 1: Atomic number\n",
    "            node_feats.append(atom.GetAtomicNum())\n",
    "            # Feature 2: Atom degree\n",
    "            node_feats.append(atom.GetDegree())\n",
    "            # Feature 3: Formal charge\n",
    "            node_feats.append(atom.GetFormalCharge())\n",
    "            # Feature 4: Hybridization\n",
    "            node_feats.append(atom.GetHybridization())\n",
    "            # Feature 5: Aromaticity\n",
    "            node_feats.append(atom.GetIsAromatic())\n",
    "            # Feature 6: Total Num Hs\n",
    "            node_feats.append(atom.GetTotalNumHs())\n",
    "            # Feature 7: Radical Electrons\n",
    "            node_feats.append(atom.GetNumRadicalElectrons())\n",
    "            # Feature 8: In Ring\n",
    "            node_feats.append(atom.IsInRing())\n",
    "            # Feature 9: Chirality\n",
    "            node_feats.append(atom.GetChiralTag())\n",
    "\n",
    "            # Append node features to matrix\n",
    "            all_node_feats.append(node_feats)\n",
    "\n",
    "        all_node_feats = np.asarray(all_node_feats)\n",
    "        return torch.tensor(all_node_feats, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ebfce71-aee2-410b-ba5d-862a79e9ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_features(mol):\n",
    "        \"\"\"\n",
    "        This will return a matrix / 2d array of the shape\n",
    "        [Number of edges, Edge Feature size]\n",
    "        \"\"\"\n",
    "        all_edge_feats = []\n",
    "\n",
    "        for bond in mol.GetBonds():\n",
    "            edge_feats = []\n",
    "            # Feature 1: Bond type (as double)\n",
    "            edge_feats.append(bond.GetBondTypeAsDouble())\n",
    "            # Feature 2: Rings\n",
    "            edge_feats.append(bond.IsInRing())\n",
    "            # Append node features to matrix (twice, per direction)\n",
    "            all_edge_feats += [edge_feats, edge_feats]\n",
    "\n",
    "        all_edge_feats = np.asarray(all_edge_feats)\n",
    "        return torch.tensor(all_edge_feats, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2debd4c3-c045-43e1-85c2-caa044f7a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency_info(mol):\n",
    "        \"\"\"\n",
    "        We could also use rdmolops.GetAdjacencyMatrix(mol)\n",
    "        but we want to be sure that the order of the indices\n",
    "        matches the order of the edge features\n",
    "        \"\"\"\n",
    "        edge_indices = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            edge_indices += [[i, j], [j, i]]\n",
    "\n",
    "        edge_indices = torch.tensor(edge_indices)\n",
    "        edge_indices = edge_indices.t().to(torch.long).view(2, -1)\n",
    "        return edge_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25faad2b-bff4-4f2b-945e-a058b9db81fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14:18:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:18:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:19:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:20:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:20:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:20:14] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "node_features = []\n",
    "edge_features = []\n",
    "edge_index = []\n",
    "for i in range(len(smiles_cleaned)):\n",
    "    mol_obj = Chem.MolFromSmiles(smiles_cleaned[i])\n",
    "    node_feature = get_node_features(mol_obj)\n",
    "    node_features.append(node_feature)\n",
    "    edge_feature = get_edge_features(mol_obj)\n",
    "    edge_features.append(edge_feature)\n",
    "    edge_adjacency = get_adjacency_info(mol_obj)\n",
    "    edge_index.append(edge_adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e774711d-0271-4a08-ac1f-43f5419d169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ProtFlash.pretrain import load_prot_flash_base\n",
    "from ProtFlash.utils import batchConverter\n",
    "data = [\n",
    "    (\"protein1\", \"KIYIVLRRRRKRVNT\"),\n",
    "]\n",
    "ids, batch_token, lengths = batchConverter(data)\n",
    "model = load_prot_flash_base()\n",
    "with torch.no_grad():\n",
    "    token_embedding = model(batch_token, lengths)\n",
    "# Generate per-sequence representations via averaging\n",
    "sequence_representations = []\n",
    "for i, (_, seq) in enumerate(data):\n",
    "    sequence_representations.append(token_embedding[i, 0: len(seq) + 1].mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05004d89-e923-4a46-ac2f-354bab83970a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87440aff-3bfd-44a9-98c1-e3789446289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_sq = sequence_representations[0]\n",
    "seq_sq = seq_sq.unsqueeze(0)\n",
    "seq_sq = seq_sq.unsqueeze(0)\n",
    "\n",
    "sequence_list=[]\n",
    "for i in range(len(node_features)):\n",
    "  sequence_list.append(seq_sq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0642e35-b0c0-4917-ad1c-e1c17f9a97b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_nodes = len(node_features)\n",
    "batch_indices = [i // batch_size for i in range(num_nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad4f9c0f-3654-4343-8417-b84b71790c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7551/1977248589.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index_data = torch.tensor(edge_index[i])\n",
      "/tmp/ipykernel_7551/1977248589.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_features_data = torch.tensor(edge_features[i])\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "for i in range(num_nodes):\n",
    "    node_features_data = node_features[i]\n",
    "    edge_index_data = torch.tensor(edge_index[i])\n",
    "    batch_idx = torch.tensor(batch_indices[i])\n",
    "    edge_features_data = torch.tensor(edge_features[i])\n",
    "    pr_seq = sequence_list[i]\n",
    "\n",
    "    data = Data(x=node_features_data, batch= batch_idx, edge_index = edge_index_data, sequence = pr_seq)\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebdabbe4-ab25-4e36-ac94-25c591223ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uzair/anaconda3/lib/python3.11/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "test_loader =  DataLoader(data_list, batch_size = batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d1c7735-b66a-4d49-a44e-afca26fab126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class channel_attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(channel_attention,self).__init__()\n",
    "        self.maxpooling = nn.AdaptiveMaxPool1d(1)\n",
    "        self.avgpooling = nn.AdaptiveAvgPool1d(1)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_features = 32, out_features = 16, bias = False),\n",
    "            nn.Linear(in_features = 16, out_features = 32, bias = False),\n",
    "            nn.ReLU(inplace = True)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        )\n",
    "            \n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x1 = self.maxpooling(x)\n",
    "        #print(x1.shape)\n",
    "        x2 = self.avgpooling(x)\n",
    "        #print(x2.shape)\n",
    "        x1_mlp = self.mlp(x1.squeeze(-1))\n",
    "        x2_mlp = self.mlp(x2.squeeze(-1))\n",
    "        feats = x1_mlp + x2_mlp\n",
    "        feats = self.activation(feats)\n",
    "        #print(feats.shape)\n",
    "        channel_refined_feats = x * feats.unsqueeze(-1)\n",
    "        return(channel_refined_feats)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14f09286-5bf8-43c3-9d8e-acc84fc146fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SAM,self).__init__()\n",
    "\n",
    "        \n",
    "        self.convlayer = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 2, out_channels = 1, kernel_size = 3, padding = 1),\n",
    "        )\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x_mean = torch.mean(x, dim = 1, keepdim = True)\n",
    "        x_max,_ = torch.max(x,dim = 1, keepdim = True)\n",
    "        x_cat = torch.cat((x_mean,x_max), dim = 1)\n",
    "        x_conv = self.convlayer(x_cat)\n",
    "        spatial_feats = self.activation(x_conv)\n",
    "        refined_spatial_feats = x * spatial_feats\n",
    "        return(refined_spatial_feats)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d7f0cc6-5094-4cc5-8c0b-76105f4ccdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CBAM,self).__init__()\n",
    "        self.channel_attention = channel_attention()\n",
    "        self.spatial_attention = SAM()\n",
    "    def forward(self,x):\n",
    "        channel_attention_layer = self.channel_attention(x)\n",
    "        spatial_attention_layer = self.spatial_attention(channel_attention_layer)\n",
    "        return(spatial_attention_layer)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ca9de82-fdae-4b4c-8280-37e48a2e2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 64\n",
    "cnn_hidden_layer = 64\n",
    "linear_embeddings = 32\n",
    "output_embeddings = 16\n",
    "out_features_cnn = 16\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN,self).__init__()\n",
    "\n",
    "        #GCN_layers\n",
    "        self.initial_GCN = GCNConv(9,embedding_size)\n",
    "        self.GCN1 = GCNConv(embedding_size,embedding_size)\n",
    "        self.GCN2 = GCNConv(embedding_size,embedding_size)\n",
    "        self.GCN_output_layer = nn.Linear(in_features = embedding_size*2, out_features = 768)\n",
    "\n",
    "        self.bn1 = nn.LayerNorm(embedding_size)\n",
    "        self.bn2 = nn.LayerNorm(embedding_size)\n",
    "\n",
    "\n",
    "\n",
    "        #CNN_layer\n",
    "        self.CNN_layers = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=2, out_channels=32, kernel_size = 3, stride=1,padding=1),\n",
    "            nn.Conv1d(in_channels=32, out_channels=32, kernel_size = 3, stride=1,padding=1),\n",
    "\n",
    "            nn.Conv1d(in_channels=32, out_channels=32, kernel_size = 3, stride=1,padding=1),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        )\n",
    "        self.pooling = nn.MaxPool1d(kernel_size = 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.cbam = CBAM()\n",
    "\n",
    "        self.CNN_linear = nn.Sequential(\n",
    "            nn.Linear(in_features= 12288, out_features = linear_embeddings),\n",
    "            nn.Softplus(),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            nn.Linear(in_features= linear_embeddings, out_features = linear_embeddings),\n",
    "            nn.Softplus(),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            nn.Linear(in_features= linear_embeddings,out_features = 1),\n",
    "            nn.Softplus()\n",
    "\n",
    "\n",
    "\n",
    "            )\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "      \n",
    "\n",
    "     \n",
    "\n",
    "      \n",
    "\n",
    "    def forward(self,drug, edge_index, batch_index, protein):\n",
    "        GCN_layer_1 = self.initial_GCN(drug, edge_index)\n",
    "        GCN_layer_1 = F.tanh(GCN_layer_1)\n",
    "\n",
    "        GCN_layer_2 = self.GCN2(GCN_layer_1, edge_index)\n",
    "        GCN_layer_2 = F.tanh(GCN_layer_2)\n",
    "\n",
    "\n",
    "        GCN_layer_3 = self.GCN2(GCN_layer_2,edge_index)\n",
    "\n",
    "\n",
    "        hidden = torch.cat([gmp(GCN_layer_3,batch_index), gap(GCN_layer_3,batch_index)],dim = 1)\n",
    "\n",
    "\n",
    "        GCN_output_layer = self.GCN_output_layer(hidden)\n",
    "        GCN_output_layer = GCN_output_layer.unsqueeze(0)\n",
    "\n",
    "\n",
    "        GCN_output_layer = GCN_output_layer.permute(1,0,2)\n",
    "        #print(f\"GCN_output : {GCN_output_layer.shape}\")\n",
    "\n",
    "        combined = torch.cat((GCN_output_layer, protein), dim = 1)\n",
    "        #print(f\"Combined_shape : {combined.shape}\")\n",
    "\n",
    "        CNN_layer = self.CNN_layers(combined)\n",
    "        CNN_layer = self.dropout(CNN_layer)\n",
    "\n",
    "        #print(f\" CNN_layer : {CNN_layer.shape}\")\n",
    "\n",
    "        attention_layer = self.cbam(x = CNN_layer)\n",
    "        pooled_attention_layer = self.pooling(attention_layer)\n",
    "        flattened_attention_layer = self.flatten(pooled_attention_layer)\n",
    "        \n",
    "\n",
    "\n",
    "        #print(flattened_attention_layer.shape)\n",
    "\n",
    "        CNN_output = self.CNN_linear(flattened_attention_layer)\n",
    "        #print(f\"CNN_output.shape : {CNN_output.shape}\")\n",
    "        ###CNN_output = CNN_output.unsqueeze(0)\n",
    "        #print(f\"CNN_output : {CNN_output}\")\n",
    "        \n",
    "        #print(f\" CNN_output shape : {CNN_output.shape}\")\n",
    "\n",
    "        ###combined_layer = torch.cat((GCN_output_layer, CNN_output), dim =0)\n",
    "        #print(f\" Combined_layer_shape: {combined_layer.shape}\")\n",
    "        ###combined_layer = combined_layer.permute(1,0,2)\n",
    "\n",
    "\n",
    "        ###combined_layer = torch.mean(combined_layer, dim = 1)\n",
    "        ###combined_layer = combined_layer.unsqueeze(1)\n",
    "        #print(f\" Combined_layer_shape: {combined_layer.shape}\")\n",
    "\n",
    "\n",
    "        ###combined_CNN_layer = self.combined_CNN_layers (combined_layer)\n",
    "        ###output_layer = self.combined_CNN_linear(combined_CNN_layer)\n",
    "\n",
    "\n",
    "        #print(combined_CNN.shape)\n",
    "        #print(model_layer.shape)\n",
    "        return(CNN_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc5028b8-7403-4239-b35f-9e42a0179076",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = GCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb0547ce-651a-449c-a4b8-0e462006ea40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.load_state_dict(torch.load(\"attention_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a88ad3f-b57a-4839-b393-cf532adc757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c45a25d-d884-47f9-a793-ef4f7660b98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (initial_GCN): GCNConv(9, 64)\n",
       "  (GCN1): GCNConv(64, 64)\n",
       "  (GCN2): GCNConv(64, 64)\n",
       "  (GCN_output_layer): Linear(in_features=128, out_features=768, bias=True)\n",
       "  (bn1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (bn2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (CNN_layers): Sequential(\n",
       "    (0): Conv1d(2, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (pooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (cbam): CBAM(\n",
       "    (channel_attention): channel_attention(\n",
       "      (maxpooling): AdaptiveMaxPool1d(output_size=1)\n",
       "      (avgpooling): AdaptiveAvgPool1d(output_size=1)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=16, bias=False)\n",
       "        (1): Linear(in_features=16, out_features=32, bias=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (spatial_attention): SAM(\n",
       "      (convlayer): Sequential(\n",
       "        (0): Conv1d(2, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (CNN_linear): Sequential(\n",
       "    (0): Linear(in_features=12288, out_features=32, bias=True)\n",
       "    (1): Softplus(beta=1, threshold=20)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): Softplus(beta=1, threshold=20)\n",
       "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (5): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.6, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15096b62-a831-47c9-81e9-d96a2f97b57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (initial_GCN): GCNConv(9, 64)\n",
       "  (GCN1): GCNConv(64, 64)\n",
       "  (GCN2): GCNConv(64, 64)\n",
       "  (GCN_output_layer): Linear(in_features=128, out_features=768, bias=True)\n",
       "  (bn1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (bn2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (CNN_layers): Sequential(\n",
       "    (0): Conv1d(2, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (pooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (cbam): CBAM(\n",
       "    (channel_attention): channel_attention(\n",
       "      (maxpooling): AdaptiveMaxPool1d(output_size=1)\n",
       "      (avgpooling): AdaptiveAvgPool1d(output_size=1)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=16, bias=False)\n",
       "        (1): Linear(in_features=16, out_features=32, bias=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (spatial_attention): SAM(\n",
       "      (convlayer): Sequential(\n",
       "        (0): Conv1d(2, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (CNN_linear): Sequential(\n",
       "    (0): Linear(in_features=12288, out_features=32, bias=True)\n",
       "    (1): Softplus(beta=1, threshold=20)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): Softplus(beta=1, threshold=20)\n",
       "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (5): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.6, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "533e8b44-a5f5-4e5d-a819-eb71cc2622ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_values_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in test_loader:\n",
    "        idx.x = idx.x.to(device)\n",
    "        idx.batch = idx.batch.to(device)\n",
    "        idx.edge_index = idx.edge_index.to(device)\n",
    "        idx.embeddings_batch = idx.sequence.to(device)\n",
    "\n",
    "        idx.edge_index = idx.edge_index.to(torch.int64)\n",
    "\n",
    "        output_test = cnn(drug=idx.x, edge_index=idx.edge_index, batch_index=idx.batch, protein= idx.embeddings_batch)\n",
    "        output_values_test.append(output_test.cpu().numpy())\n",
    "\n",
    "# Flatten the output and ground truth arrays\n",
    "output_value_model_test = np.concatenate(output_values_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0fdf1bbc-af12-44f2-a2d5-f9e0f1fdc61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model = []\n",
    "for i in range(len(output_value_model_test)):\n",
    "    output = torch.tensor(output_value_model_test[i])\n",
    "    output_model.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80c1b34d-e48c-410c-a3b7-d17b12500e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1036736"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0bee6f8b-0a7a-4363-ae11-bd872aff5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sort = np.argsort(output_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c42d7431-84f6-42c8-ae09-9fa8cf04d6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1036736"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_value_model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bcd9fd30-8c7b-4769-8262-3368119f559c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5324)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_log[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d74e5ed4-55c4-4f3a-b9d4-b4b17dc04aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.629501 , 7.072581 , 3.2077932, ..., 5.571663 , 7.2749705,\n",
       "       3.0805588], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_value_model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deb665aa-c2af-49b6-a47f-54f9b33c73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sort = np.argsort(output_value_model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b59963ce-fa80-49f0-857f-067a4791cf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([857613, 408800, 917404, ..., 876393, 108486, 166486])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ecbe3cc-2475-405e-833a-91574dd05340",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ki = output_sort[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c7d4597f-dd26-4608-a80e-99d04456328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_log = log_sort[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "697a0e4c-85dc-4a28-8893-6be0c71df6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "smiles_sorted = []\n",
    "drug_ids = []\n",
    "for i in range(len(sorted_ki)):\n",
    "    index = sorted_ki[i]\n",
    "    values.append(output_value_model_test[index])\n",
    "    smiles_sorted.append(smiles_cleaned[index])\n",
    "    drug_ids.append(drug_cleaned[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28f227e6-f4cf-423a-ad09-9d418c7394c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({\"CHEMBL ID\" : drug_ids, \"Smiles\" : smiles_sorted, \"Ki_values(predicted)\" : values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4afc819c-509c-43a7-9e06-c74b2a0ac07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(\"attention_model_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e17b3ef-807c-4ad6-8952-d722adaa8a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_log = []\n",
    "smiles_sorted = []\n",
    "drug_ids = []\n",
    "for i in range(len(sorted_log)):\n",
    "    index = sorted_log[i]\n",
    "    values_log.append(output_log[index])\n",
    "    smiles_sorted.append(smiles_cleaned[index])\n",
    "    drug_ids.append(drug_cleaned[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9259534f-07dd-40b2-9f70-4aa25957a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({\"CHEMBL ID\" : drug_ids, \"Smiles\" : smiles_sorted, \"Ki_values(predicted)\" : values_log})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a0ac9953-0726-4111-8bb7-e0afcfc0234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(\"dopamine_drug_predictions_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a25b7c-05f2-4470-9fda-8110b6ad47ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
